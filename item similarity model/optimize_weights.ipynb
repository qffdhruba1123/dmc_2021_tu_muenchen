{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import pytz\n",
    "from operator import itemgetter\n",
    "import fasttext\n",
    "import csv\n",
    "from difflib import SequenceMatcher\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "base_path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pd.read_csv(\"./train_data_with_sim.csv\").set_index(\"itemID_test\", drop=False)\n",
    "\n",
    "best_5_trans = pd.read_csv(f\"./data/best_5.csv\").set_index(\"itemId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40176.0, 45060.0, 45872.0, 57687.0, 60257.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_5_trans.loc[817.0]['rec'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>817.0</th>\n",
       "      <td>40176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817.0</th>\n",
       "      <td>45060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817.0</th>\n",
       "      <td>45872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817.0</th>\n",
       "      <td>57687.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817.0</th>\n",
       "      <td>60257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168.0</th>\n",
       "      <td>6128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168.0</th>\n",
       "      <td>26028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168.0</th>\n",
       "      <td>37813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168.0</th>\n",
       "      <td>41877.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168.0</th>\n",
       "      <td>50925.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rec\n",
       "itemId         \n",
       "817.0   40176.0\n",
       "817.0   45060.0\n",
       "817.0   45872.0\n",
       "817.0   57687.0\n",
       "817.0   60257.0\n",
       "1168.0   6128.0\n",
       "1168.0  26028.0\n",
       "1168.0  37813.0\n",
       "1168.0  41877.0\n",
       "1168.0  50925.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_5_trans.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21310.0, 73018.0, 19194.0, 40250.0, 46107.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df.head(5)\n",
    "[21310.0, 73018.0, 19194.0, 40250.0, 46107.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['a', 'b']\n",
    "weights = [1, 2]\n",
    "\n",
    "{key: value for (key, value) in zip(columns, weights)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinations: {'sim_title': 0.44539642992930695, 'sim_author': 0.1811377104785857, 'sim_lang': 0.08914077866552864, 'sim_publisher': 0.28106675008179, 'sim_mainTopic': 0.0032583308447887336, 'score': 1.3529411764705883}\n",
      "Found in iteration: 179\n",
      "Combinations: {'sim_title': 0.2880618955299064, 'sim_author': 0.16485819515896538, 'sim_lang': 0.2056062788317603, 'sim_publisher': 0.3392215524836328, 'sim_mainTopic': 0.002252077995735114, 'score': 1.3529411764705883}\n",
      "Found in iteration: 1167\n",
      "Combinations: {'sim_title': 0.4488124693639955, 'sim_author': 0.07931618373976651, 'sim_lang': 0.033701094979653325, 'sim_publisher': 0.4296711196830966, 'sim_mainTopic': 0.008499132233488008, 'score': 1.3529411764705883}\n",
      "Found in iteration: 1504\n"
     ]
    }
   ],
   "source": [
    "def get_rand_weights(n):\n",
    "    weights = rand(n)\n",
    "#     weights=np.array([0.3, 0.2, 0.2, 0.3])\n",
    "    sum_weights = sum(weights)\n",
    "    norm_weights = weights / sum_weights\n",
    "    \n",
    "    return norm_weights\n",
    "\n",
    "def get_score(item, w_c):\n",
    "    score = 0\n",
    "    for weight, column in w_c:\n",
    "        product = weight * item[column]\n",
    "        score = score + product\n",
    "        \n",
    "    return score\n",
    "\n",
    "def evaluate(orig_recoms, gen_recoms):\n",
    "    \n",
    "#     print(f'\\tOrig Ids = {orig_recoms}\\n\\tRec Ids = {gen_recoms}')\n",
    "    \n",
    "    common_items = set(orig_recoms).intersection(set(gen_recoms))\n",
    "    \n",
    "    score = len(common_items)\n",
    "    \n",
    "#     print(f'\\tCommon items: {score}')\n",
    "    return score\n",
    "\n",
    "\n",
    "def test(test_ids, w_c, n=5):\n",
    "    total_eval_score = 0\n",
    "    \n",
    "    for test_id in test_ids:\n",
    "#         print(f'Evaluation test id: {test_id}\\n')\n",
    "        train = sim_df.loc[test_id]\n",
    "        scores = []\n",
    "        for index, row in train.iterrows():\n",
    "            score = get_score(row, w_c)\n",
    "            scores.append({\n",
    "                'rec_id': row['itemID_orig'],\n",
    "                'score': score,\n",
    "            })\n",
    "        \n",
    "        top_n = sorted(scores, key=itemgetter('score'), reverse=True)[:n]\n",
    "        top_n_rec_id = [ n['rec_id'] for n in top_n ]\n",
    "        \n",
    "        eval_score = evaluate(\n",
    "            orig_recoms=best_5_trans.loc[test_id]['rec'].tolist(), # TODO: Can avoid creating list everytimne\n",
    "            gen_recoms=top_n_rec_id\n",
    "        )\n",
    "        \n",
    "        total_eval_score = total_eval_score + eval_score\n",
    "    \n",
    "    \n",
    "    avg_score = total_eval_score / len(test_ids)\n",
    "    \n",
    "    return avg_score\n",
    "\n",
    "\n",
    "def optimize(test_ids, no_iter=2):\n",
    "    features = ['sim_title', 'sim_author', 'sim_lang', 'sim_publisher', 'sim_mainTopic']\n",
    "    f_size = len(features)\n",
    "    tot_iter = no_iter\n",
    "    \n",
    "    best_score=1.35\n",
    "    \n",
    "    weights_with_score = []\n",
    "    while(no_iter > 0):\n",
    "        weights = get_rand_weights(f_size)\n",
    "        w_c = list(zip(weights, features))\n",
    "        \n",
    "        w_c_dict = {key: value for (key, value) in zip(features, weights)}\n",
    "#         print(f'Trying combinations: {w_c_dict}')\n",
    "    \n",
    "        score = test(test_ids, w_c)\n",
    "        \n",
    "#         print(f'\\tGot score: {score}')\n",
    "        \n",
    "        w_c_dict['score'] = score\n",
    "        weights_with_score.append(w_c_dict)\n",
    "        \n",
    "        no_iter = no_iter - 1\n",
    "        \n",
    "        if(score>=best_score):\n",
    "            print(f'Combinations: {w_c_dict}')\n",
    "            print(f'Found in iteration: {tot_iter - no_iter}')\n",
    "            best_score=score\n",
    "    \n",
    "    return weights_with_score\n",
    "\n",
    "# 17 items\n",
    "interest_ids = [\n",
    "   27903, 51133, 11609,  8318, 24603, 15767, 77956, 39308,\n",
    "   28844, 56282, 817, 71784, 41648, 61593, 61125, 21497,\n",
    "   51443\n",
    "]\n",
    "test_ids = interest_ids\n",
    "# test_ids = sim_df.itemID_test.unique()\n",
    "\n",
    "weights_with_score = optimize(test_ids, no_iter=2000)\n",
    "\n",
    "# 0 - 5 score, 5 means all match, 0 means no match\n",
    "pd.DataFrame(weights_with_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights found so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "default 0.3,0.2,0.2,0.3 gives 1.35\n",
    "\n",
    "Trying combinations: {'sim_title': 0.054073284352889384, 'sim_author': 0.7851049324817732, 'sim_lang': 0.5915191750574874, 'sim_publisher': 0.5407117177241336}\n",
    "\tGot score: 1.1764705882352942\n",
    "Trying combinations: {'sim_title': 0.3758848200149616, 'sim_author': 0.3743017618277995, 'sim_lang': 0.6808498026325662, 'sim_publisher': 0.8222389929077665}\n",
    "\tGot score: 1.2352941176470589\n",
    "Trying combinations: {'sim_title': 0.9420405541118271, 'sim_author': 0.07735137025517957, 'sim_lang': 0.244343637953351, 'sim_publisher': 0.27282294928471773}\n",
    "\tGot score: 1.0588235294117647\n",
    "Trying combinations: {'sim_title': 0.7661827322387778, 'sim_author': 0.3919521836823401, 'sim_lang': 0.17557108142049027, 'sim_publisher': 0.1741377537215386}\n",
    "\tGot score: 1.2352941176470589\n",
    "Trying combinations: {'sim_title': 0.2002006161924058, 'sim_author': 0.5735477108252497, 'sim_lang': 0.8302436363185348, 'sim_publisher': 0.1406282197715728}\n",
    "\tGot score: 1.0\n",
    "Trying combinations: {'sim_title': 0.23053689664614396, 'sim_author': 0.6441760206271187, 'sim_lang': 0.346272601577822, 'sim_publisher': 0.1550816744696888}\n",
    "\tGot score: 1.2941176470588236\n",
    "Trying combinations: {'sim_title': 0.3107973473412178, 'sim_author': 0.9428192648226833, 'sim_lang': 0.6012854912648783, 'sim_publisher': 0.8357129296230348}\n",
    "\tGot score: 1.2941176470588236\n",
    "Trying combinations: {'sim_title': 0.24013393713722053, 'sim_author': 0.6136094171259088, 'sim_lang': 0.5802855651370925, 'sim_publisher': 0.7510439496614834}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(weights_with_score).to_csv(\"W_SC_11_6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.read_pickle(\"./main_topic_clusters.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pandas._libs.index.IndexEngine._call_map_locations'\n",
      "Traceback (most recent call last):\n",
      "  File \"pandas\\_libs\\hashtable_class_helper.pxi\", line 1709, in pandas._libs.hashtable.PyObjectHashTable.map_locations\n",
      "TypeError: unhashable type: 'list'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[F, M]       6344\n",
       "[F, M, X]     808\n",
       "[F, M, H]     665\n",
       "[F, M, W]     422\n",
       "[F, M, T]     299\n",
       "[F, M, M]     257\n",
       "[F, M, K]     256\n",
       "[F, K, M]     147\n",
       "[F, X, M]      70\n",
       "[X, Q, M]      23\n",
       "[F, J, M]      13\n",
       "[5, A, M]       2\n",
       "[F, N, M]       1\n",
       "[P, G, M]       1\n",
       "[J, M, U]       1\n",
       "Name: main_topic_split, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[clusters.main_topic_cluster==3].main_topic_split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
