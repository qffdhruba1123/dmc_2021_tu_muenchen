{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load recommendations from level 1\n",
    "with open('recommendations_all_level2_features.pkl', 'rb') as f:\n",
    "    rec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'itemId', 'rec_id', 'weight', 'source', 'title_x',\n",
       "       'author_x', 'publisher_x', 'main_topic_item', 'subtopics_item',\n",
       "       'title_y', 'author_y', 'publisher_y', 'main_topic_rec', 'subtopics_rec',\n",
       "       'confItemVsRec', 'titleLength', 'identical', 'pages_mean_item',\n",
       "       'pages_mean_rec', 'max_pageCount', 'Euc_distance', 'rel_distance',\n",
       "       'score', 'g_categories_item', 'g_categories_rec', 'main_topic_item',\n",
       "       'main_topic_rec', 'subtopics_item', 'subtopics_rec',\n",
       "       'main_topic_cluster_item', 'main_topic_cluster_rec', 'category_match',\n",
       "       'suptopics_matches_count', 'suptopics_matches_weight',\n",
       "       'main_topic_cluster_match', 'weighted_average_rating',\n",
       "       'total_ratings_count', 'total_ratings_count_log_scaled', 'itemID_merge',\n",
       "       'prices_mean_rec', 'prices_mean_item', 'eucl_distance', 'score',\n",
       "       'cover_similarity_score_squared'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### drop columns that are not needed\n",
    "rec = rec.drop(['Unnamed: 0',\n",
    "                 'pages_mean_item', 'pages_mean_rec', 'max_pageCount', 'Euc_distance', 'rel_distance',\n",
    "               'g_categories_item', 'g_categories_rec', 'main_topic_item', 'main_topic_rec',\n",
    "               'subtopics_item', 'subtopics_rec', 'main_topic_cluster_item', 'main_topic_cluster_rec',\n",
    "                'suptopics_matches_count',\n",
    "               'itemID_merge', 'prices_mean_rec', 'prices_mean_item',\n",
    "                'eucl_distance'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['itemId', 'rec_id', 'weight', 'source', 'title_x', 'author_x',\n",
       "       'publisher_x', 'title_y', 'author_y', 'publisher_y', 'confItemVsRec',\n",
       "       'titleLength', 'identical', 'score', 'category_match',\n",
       "       'suptopics_matches_weight', 'main_topic_cluster_match',\n",
       "       'weighted_average_rating', 'total_ratings_count',\n",
       "       'total_ratings_count_log_scaled', 'score',\n",
       "       'cover_similarity_score_squared'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename to differentiate \"scores\"\n",
    "rec.columns = ['itemId', 'rec_id', 'weight', 'source', 'title_x', 'author_x',\n",
    "       'publisher_x', 'title_y', 'author_y', 'publisher_y', 'confItemVsRec',\n",
    "       'titleLength', 'identical', 'score_pages', 'category_match',\n",
    "       'suptopics_matches_weight', 'main_topic_cluster_match',\n",
    "       'weighted_average_rating', 'total_ratings_count',\n",
    "       'total_ratings_count_log_scaled', 'score_price',\n",
    "       'cover_similarity_score_squared']\n",
    "#rec = rec.drop(['score'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Final Level 2 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORY FEATURE\n",
    "def create_l2_category_feature(df):\n",
    "    rec = df\n",
    "    rec['l2_category_feature'] = np.NaN\n",
    "    for i in range(0, len(rec)):\n",
    "        category_match = rec.iloc[i]['category_match']\n",
    "        #main_topic_seqmatch = rec.iloc[i]['main_topic_seqmatch']\n",
    "        suptopics_matches_weight = rec.iloc[i]['suptopics_matches_weight']\n",
    "        main_topic_cluster_match = rec.iloc[i]['main_topic_cluster_match']\n",
    "        \n",
    "        if pd.isnull(category_match) == True:\n",
    "            # no category_match exists\n",
    "            # exclude from calculation    \n",
    "            # calculate final category feature\n",
    "            cat_feature = 0.7 * main_topic_cluster_match + 0.3 * suptopics_matches_weight\n",
    "            rec.at[i, 'l2_category_feature'] = cat_feature\n",
    "        else: \n",
    "            # category_match exists:\n",
    "            cat_feature = 0.5 * main_topic_cluster_match + 0.3 * category_match + 0.2 * suptopics_matches_weight\n",
    "            rec.at[i, 'l2_category_feature'] = cat_feature\n",
    "    return rec['l2_category_feature']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_l2_cover_feature_hao(df):\n",
    "    rec = df\n",
    "    rec['l2_cover_feature'] = np.NaN\n",
    "    for i in range(0, len(rec)):\n",
    "        similarity = rec.iloc[i]['cover_similarity_score_squared']\n",
    "        \n",
    "        if similarity == 0:\n",
    "            cover_feature = np.NaN\n",
    "            rec.at[i, 'l2_cover_feature'] = cover_feature\n",
    "        else:\n",
    "            cover_feature = similarity\n",
    "            rec.at[i, 'l2_cover_feature'] = cover_feature\n",
    "    return rec['l2_cover_feature']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVER FEATURE\n",
    "def create_l2_cover_feature(df):\n",
    "    rec = df\n",
    "    rec['l2_cover_feature'] = np.NaN\n",
    "    for i in range(0, len(rec)):\n",
    "        structural_similarity = rec.iloc[i]['structural_similarity']\n",
    "        hist_correlation = rec.iloc[i]['hist_correlation']\n",
    "        #main_color_euc_distance_norm = rec.iloc[i]['main_color_euc_distance_norm']\n",
    "        \n",
    "        if pd.isnull(hist_correlation) == True:\n",
    "            # no rating exists\n",
    "            # cannot calculate a feature\n",
    "            cover_feature = np.NaN\n",
    "            rec.at[i, 'l2_cover_feature'] = cover_feature\n",
    "        \n",
    "        else:\n",
    "            # hist_correlation and struct_sim are not always between -1 and 1\n",
    "            # control for that\n",
    "            if hist_correlation < -1:\n",
    "                hist_correlation = -1\n",
    "            if structural_similarity < -1:\n",
    "                structural_similarity = -1\n",
    "            if hist_correlation > 1:\n",
    "                hist_correlation = 1\n",
    "            if structural_similarity > 1:\n",
    "                structural_similarity = 1\n",
    "\n",
    "            # calculate final feature\n",
    "            cover_feature = 0.5 * (structural_similarity+1)/2 +  0.5 * (hist_correlation+1)/2 #+ 0.2 * main_color_euc_distance_norm\n",
    "            rec.at[i, 'l2_cover_feature'] = cover_feature\n",
    "\n",
    "    return rec['l2_cover_feature']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORY FEATURE\n",
    "def create_l2_rating_feature(df):\n",
    "    rec = df\n",
    "    rec['l2_rating_feature'] = np.NaN\n",
    "    \n",
    "    # scale rating \n",
    "    values = rec['weighted_average_rating']\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    null_index = rec['weighted_average_rating'].isnull()\n",
    "    rec.loc[~null_index, ['weighted_average_rating']] = min_max_scaler.fit_transform(rec.loc[~null_index, ['weighted_average_rating']])\n",
    "    \n",
    "    for i in range(0, len(rec)):\n",
    "        weighted_average_rating = rec.iloc[i]['weighted_average_rating']\n",
    "        total_ratings_count_log_scaled = rec.iloc[i]['total_ratings_count_log_scaled']\n",
    "        \n",
    "        if pd.isnull(weighted_average_rating) == True:\n",
    "            # no rating exists\n",
    "            # cannot calculate a feature\n",
    "            feature = np.NaN\n",
    "            rec.at[i, 'l2_rating_feature'] = feature\n",
    "        else: \n",
    "            # rating exists\n",
    "            feature = 0.8 * weighted_average_rating +  0.2 * total_ratings_count_log_scaled\n",
    "            rec.at[i, 'l2_rating_feature'] = feature\n",
    "    return rec['l2_rating_feature']   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set empty value to 0 otherwise to 1\n",
    "def return_0_or_1(cat):\n",
    "    if pd.isna(cat):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "#set empty value to 0 otherwise return original\n",
    "def set_nan_to_0(cat):\n",
    "    if pd.isna(cat):\n",
    "        return 0\n",
    "    else:\n",
    "        return cat\n",
    "def calc_weight(category,cover,rating,price,pages):\n",
    "    #calculate nenner - set weight of missing values to 0\n",
    "    nenner = return_0_or_1(category)*0.25 + return_0_or_1(cover)*0.25 + return_0_or_1(rating)*0.225 + return_0_or_1(price)*0.05 + return_0_or_1(pages)*0.225\n",
    "    if nenner == 0:\n",
    "        weight = 0\n",
    "    else:\n",
    "        #calculate weight, replace missing values with 0 - otherwise nan will be returned whenever there is a nan value in the sum\n",
    "        weight = 0.25/nenner * set_nan_to_0(category) + 0.25/nenner * set_nan_to_0(cover) + 0.225/nenner * set_nan_to_0(rating) + 0.05/nenner * set_nan_to_0(price) + 0.225/nenner * set_nan_to_0(pages)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_l2_overall_feature(df):\n",
    "    rec = df\n",
    "    rec['l2_overall_feature'] = np.NaN\n",
    "    \n",
    "    for i in range(0, len(rec)):\n",
    "        category = rec.iloc[i]['l2_category_feature']\n",
    "        cover = rec.iloc[i]['l2_cover_feature']\n",
    "        rating = rec.iloc[i]['l2_rating_feature']\n",
    "        price = rec.iloc[i]['score_price']\n",
    "        pages = rec.iloc[i]['score_pages']\n",
    "        \n",
    "        #### PROBLEM: HOW do I deal with NaN values of final scores??? \n",
    "        # if not controlled: huge bias @Maurice\n",
    "        # solution: dynamically updating the \"Nenner\"\n",
    "        \n",
    "        feature = calc_weight(category, cover, rating, price, pages)\n",
    "        rec.at[i, 'l2_overall_feature'] = feature\n",
    "    return rec['l2_overall_feature']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec['l2_category_feature'] = create_l2_category_feature(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec['l2_cover_feature'] = create_l2_cover_feature_hao(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec['l2_rating_feature'] = create_l2_rating_feature(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec['l2_overall_feature'] = create_l2_overall_feature(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the so far recommendations \n",
    "with open('recommendations_final_20210628.pkl', 'wb') as f:\n",
    "    pickle.dump(rec, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load recommendations from level 1\n",
    "with open('recommendations_final_20210628.pkl', 'rb') as f:\n",
    "    rec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep only 5 best recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_final = rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort recommendations by itemID, then by weight so best recommendation comes first\n",
    "rec_final = rec_final.sort_values(by=['itemId', 'final_weight'], ascending = (True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_final = rec_final.groupby('itemId').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['itemId', 'rec_id', 'weight', 'source', 'title_x', 'author_x',\n",
       "       'publisher_x', 'title_y', 'author_y', 'publisher_y', 'confItemVsRec',\n",
       "       'titleLength', 'identical', 'score_pages', 'score_price',\n",
       "       'l2_category_feature', 'l2_cover_feature', 'l2_rating_feature',\n",
       "       'l2_overall_feature', 'final_weight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_final = rec_final.drop(['weight', 'source', 'title_x', 'author_x',\n",
    "       'publisher_x', 'title_y', 'author_y', 'publisher_y', 'confItemVsRec',\n",
    "       'titleLength', 'identical', 'score_pages', 'score_price',\n",
    "       'l2_category_feature', 'l2_cover_feature', 'l2_rating_feature',\n",
    "       'l2_overall_feature'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_final = rec_final.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_final = rec_final.drop(['index'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemId</th>\n",
       "      <th>rec_id</th>\n",
       "      <th>final_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>65244</td>\n",
       "      <td>0.355841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>17952</td>\n",
       "      <td>0.330349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>30847</td>\n",
       "      <td>0.285754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>50607</td>\n",
       "      <td>0.278370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>72230</td>\n",
       "      <td>0.255124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>79016</td>\n",
       "      <td>53240</td>\n",
       "      <td>0.846500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>79016</td>\n",
       "      <td>22802</td>\n",
       "      <td>0.559320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>79016</td>\n",
       "      <td>77768</td>\n",
       "      <td>0.452185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>79016</td>\n",
       "      <td>6624</td>\n",
       "      <td>0.435231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>79016</td>\n",
       "      <td>46681</td>\n",
       "      <td>0.190894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      itemId  rec_id  final_weight\n",
       "0         12   65244      0.355841\n",
       "1         12   17952      0.330349\n",
       "2         12   30847      0.285754\n",
       "3         12   50607      0.278370\n",
       "4         12   72230      0.255124\n",
       "...      ...     ...           ...\n",
       "4995   79016   53240      0.846500\n",
       "4996   79016   22802      0.559320\n",
       "4997   79016   77768      0.452185\n",
       "4998   79016    6624      0.435231\n",
       "4999   79016   46681      0.190894\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the so far recommendations \n",
    "with open('recommendations_final_20210628_top5.pkl', 'wb') as f:\n",
    "    pickle.dump(rec_final, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
